{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501aba42",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "我们要解决的问题是：识别手写数字。\n",
    "\n",
    "问题的输入：是一张灰度图像像素是 28 * 28。\n",
    "问题的输出：是这张图片上的手写数字是几（0-9）\n",
    "\n",
    "我们训练需要用到的数据源是 MNIST 包含 6W 张训练图像，1W 张测试图像\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ba680",
   "metadata": {},
   "source": [
    "# 1、数据集\n",
    "首先我们需要先加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961470f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 23:00:36.659131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d3afd",
   "metadata": {},
   "source": [
    "train_images 和 train_labels 是训练集的数据和标签，train_images 是所有的训练数据。我们先来看一下数据的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5a1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "digit=train_images[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de232c50",
   "metadata": {},
   "source": [
    "train_images 是一个三维数组，表示的含义是 60000 个 28*28的二维数组。\n",
    "\n",
    "每一个 28 * 28 的数组就是一张有 28 * 28 个像素的图片。\n",
    "\n",
    "数组的值就是像素的值。我们找其中一个数组看一下。数值越大，颜色越黑，0是白色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa26cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 55, 148, 210, 253, 253, 113, 87, 148, 55, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87, 232, 252, 253, 189, 210, 252, 252, 253, 168, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 57, 242, 252, 190, 65, 5, 12, 182, 252, 253, 116, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 96, 252, 252, 183, 14, 0, 0, 92, 252, 252, 225, 21, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 132, 253, 252, 146, 14, 0, 0, 0, 215, 252, 252, 79, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 126, 253, 247, 176, 9, 0, 0, 8, 78, 245, 253, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 16, 232, 252, 176, 0, 0, 0, 36, 201, 252, 252, 169, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 22, 252, 252, 30, 22, 119, 197, 241, 253, 252, 251, 77, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 16, 231, 252, 253, 252, 252, 252, 226, 227, 252, 231, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 55, 235, 253, 217, 138, 42, 24, 192, 252, 143, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 255, 253, 109, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 71, 253, 252, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 252, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 71, 253, 252, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 106, 253, 252, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 255, 253, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 218, 252, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 96, 252, 189, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 184, 252, 170, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 147, 252, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit=train_images[4]\n",
    "\n",
    "# 打印数组\n",
    "for arr in digit:\n",
    "    print(arr.tolist())\n",
    "# 打印图片\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b289d6a",
   "metadata": {},
   "source": [
    "而 train_labels 就是每张图片对应的具体数字。我们看一下它的结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee47852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[5 0 4 ... 5 6 8]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels)\n",
    "print(train_labels[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a836d7",
   "metadata": {},
   "source": [
    "是一个一维数组，一共有 60000 个元素，正好与 train_images 的照片数量对应。上面我们输出了下标是 4 的图片，是一张 9 ，而对应的 label 也是9\n",
    "\n",
    "test_images, test_labels 也是同样的结构，只不过图片数量是10000张。\n",
    "\n",
    "\n",
    "总结一下，我们的输入是一张图片，它是用一个 28 * 28  的数组表示的，数组的值是像素值，取值范围是 [0,255]。数值越大，颜色越黑，每一个数组都有一个对应的标签（label），值是，图片上的对应的数字。\n",
    "\n",
    "现在我们有60000组训练数据，有10000组测试数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9ba35",
   "metadata": {},
   "source": [
    "# 2、构建网络架构\n",
    "神经网络的核心组件是层（layer），神经网络的层是数据处理模块，它将输入的数据进行处理，然后将输出的数据输入到下一个神经网络的层。每一个神经网络的层会有多个单元。\n",
    "\n",
    "下面我们搭建一个两层的神经网络。用来解决 MNIST 的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b1fd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 23:00:39.595589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network=models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28, )))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec43496",
   "metadata": {},
   "source": [
    "上面使用的层叫 Dense 层。是密集连接层，也叫全连接层，第一层是一个包含 512 个神经元的层，它的输入是一个 28 * 28 的数组(是一个形状为(28 * 28,1)的数组)。\n",
    "\n",
    "第二层的输入是第一层的输出结果，第二层的输出是一个包含10个元素的数组（形状为（10,1））。每一个数值代表的是图片上的数字的概率。\n",
    "\n",
    "下面是这个神经网络的结构图，由于节点太多，这里做了简化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f7db",
   "metadata": {},
   "source": [
    "![](./resource/MNIST_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469a180",
   "metadata": {},
   "source": [
    " # 3、编译网络\n",
    " 编译网络主要是指定三个参数。\n",
    " + 损失函数：损失函数用来评估训练数据的性能，即评估预测值和实际值的差距，以便调整神经网络的参数。\n",
    " + 优化器：根据损失函数和训练数据来更新网络的机制。\n",
    " + 指标：在训练和测试时关注的指标。本例我们只关注预测正确的图片的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4ccd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf77713b",
   "metadata": {},
   "source": [
    "# 4、数据处理\n",
    "在开始训练之前需要对数据进行处理一下。首先需要将之前形状为（60000,28,28）取值范围在[0,255]的图片数据转换成 （60000,28 * 28）取值范围为[0,1]二维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04c474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape((60000, 28 * 28))\n",
    "train_images=train_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "test_images=test_images.reshape((10000, 28 * 28))\n",
    "test_images=test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c5902",
   "metadata": {},
   "source": [
    "我们输出下形状看一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1084c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed00c4",
   "metadata": {},
   "source": [
    "我们还需要对标签进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755d059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44a229",
   "metadata": {},
   "source": [
    "我们输出一下结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08834fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367e4e7",
   "metadata": {},
   "source": [
    "每个标签处理后，是一个长度为10的数组，数组的值是0或者1，如果标签的的原始值 是9 那么对应的数组 a[9] = 1 ,其他位置都是0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275372bf",
   "metadata": {},
   "source": [
    "# 5、训练网络\n",
    "\n",
    "下面开始训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0114788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2544 - accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1024 - accuracy: 0.9697\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9799\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0485 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x153445d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d479d8f",
   "metadata": {},
   "source": [
    "我们使用的是训练数据进行的训练。batch_size 表示的是批次大小。每次我们使用128张图片进行训练，训练数据一共是60000张数据，所以一次完整的训练需要分为 469 个批次。epochs 是迭代次数，我们一共迭代了5次。每次迭代的结果都会输出loss，即损失和 accuracy 精度。我们经过5次迭代，最终达到的精度是 98.8%\n",
    "\n",
    "**PS:需要注意的是，如果你使用的是 jupyter，切记不要重复允许 fit 方法，如果需要重新运行，请重启内核**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39533e7e",
   "metadata": {},
   "source": [
    "# 6、测试网络\n",
    "我们在测试集上进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c23fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9758\n",
      "test_acc: 0.9757999777793884\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97019e0",
   "metadata": {},
   "source": [
    "测试集精度是 98.1% 比训练集要低，这种现象叫 **过拟合（overfit）**。 是指模型在新的数据集上的性能比在训练集上的性能要差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203cfe4",
   "metadata": {},
   "source": [
    "# 7、神经网络内部到底在做什么\n",
    "\n",
    "下面我们从数据角度理解下这个神经网络到底在做什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b2064",
   "metadata": {},
   "source": [
    "## 7.1 输入层\n",
    "输入层的数据起始很简单，就是我们处理好的训练数据，准确的说是 train_images 这个形状是（60000, 784）的数组，这个数组的每一列都是一张28 * 28的灰度图片被打平的。然后我们还将这个数组的每一个值都除了一下 255。所以数组的值的取值范围是 [0,1]。输入层的每一个节点都表示一个数值。\n",
    "\n",
    "所以输入层一共有 28 * 28 = 784 个节点，每次输入一列数据（一张图片的数据）。\n",
    "\n",
    "我们把输入层的神经元从上到下依次标记为  a<sup>[0]</sup><sub>1</sub>、 a<sup>[0]</sup><sub>2</sub> 、、、a<sup>[0]</sup><sub>784</sub>。所以输入层的每一个节点都是一个像素的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f324f3e5",
   "metadata": {},
   "source": [
    "## 7.2 第一层神经网络\n",
    "第一层神经网络，也就是上面图里包含 512 个节点的那一层，我们先看这一层的第一个节点。如下图\n",
    "\n",
    "![](./resource/MNIST_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204aa26",
   "metadata": {},
   "source": [
    "这个节点做的事情也很简单。首先把 输入层输入的所有数相加，但是每个数都有一个权重。计算的公式如下：\n",
    "\n",
    "z<sup>[1]</sup><sub>1</sub> = w<sub>1</sub> * a<sup>[0]</sup><sub>1</sub> + w<sub>2</sub> * a<sup>[0]</sup><sub>2</sub> + .... + w<sub>784</sub> * a<sup>[0]</sup><sub>784</sub> + b<sub>1</sub>\n",
    "\n",
    "得到 z<sup>[1]</sup><sub>1</sub> 之后，会使用 relu 函数，计算 a<sup>[1]</sup><sub>1</sub>。 relu 函数 如下图：\n",
    "\n",
    "![](./resource/MNIST_03.png)\n",
    "\n",
    "函数的图像如下图：\n",
    "\n",
    "![](./resource/MNIST_04.png)\n",
    "\n",
    "我们把 z<sup>[1]</sup><sub>1</sub> 输入到 relu 函数中，会得到一个数值 这个数值就是 第一层神经网络的第一个节点的输出。 a<sup>[1]</sup><sub>1</sub>。\n",
    "\n",
    "节点会保存所有 w 的值，并且在创建神经网络的时候**随机初始化** 所有 w 的值。\n",
    "\n",
    "\n",
    "第一层神经网络的所有节点都会执行上面的两步操作，唯一的区别就是，每一个节点的 w 的数值是不一样的，所以在这一层我们一共有 512 * 784 个 w 数值。\n",
    "\n",
    "当这一层的所有节点都执行完成后。 我们会得到 一个 [1,512] 的二维数组，数组就一列，每一行就一个元素。就是第一层神经网络输出的 a 值。如下图：\n",
    "\n",
    "![](./resource/MNIST_05.png)\n",
    "\n",
    "现在我们已经有了第一层神经网络的输出。也就是第二层神经网络的输入。即  [1,512]  的数组。下面我们来看第二层神经网络。\n",
    "\n",
    "## 7.3 第二层神经网络\n",
    "第二层神经网络是我们看到的最后一层，这一层一共包含 10 个节点。每个节点也会输出一个数值，范围也是(0,1) 代表的含义是这张图片上的数字是多少的概率。第一个节点代表数字是 0 的概率，第二个节点代表数字是 1 的概率。以此类推，我们可以知道，这 10 个接点输出的值加起来一共是 1 。\n",
    "\n",
    "这些节点做的事情也很简单，跟第一层神经网络类似。我们还是先拿其中一个节点来看。\n",
    "\n",
    "![](./resource/MNIST_06.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807dc99",
   "metadata": {},
   "source": [
    "这个节点会接收第一层神经网络输入的 512 个数值，然后对这些参数按照一定的权重进行加和得到 z<sup>[2]</sup><sub>1</sub>\n",
    "\n",
    "z<sup>[2]</sup><sub>1</sub> = w<sub>1</sub> * a<sup>[1]</sup><sub>1</sub> + w<sub>2</sub> * a<sup>[1]</sup><sub>2</sub> + .... + w<sub>512</sub> * a<sup>[1]</sup><sub>512</sub> + b<sub>1</sub>\n",
    "\n",
    "得到 z<sup>[2]</sup><sub>1</sub>  之后，再计算 e<sup>z<sup>[2]</sup><sub>1</sub> 的值（e 是自然常数）。\n",
    "    \n",
    "当第二层的所有节点都计算结束后，对所有节点得到的数值进行求和。然后再用每一个节点计算的值，除以总和，就得到了最终的输出 a<sup>[2]</sup> 。\n",
    "\n",
    "说起来比较复杂，下面用图形描述一下计算过程。\n",
    "    \n",
    "![](./resource/MNIST_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992f876",
   "metadata": {},
   "source": [
    "上面的图就是 softmax 函数的计算过程，用函数表示就是下面这种：\n",
    "\n",
    "![](./resource/MNIST_08.png)\n",
    "\n",
    "由于上一层一共有 512 个节点，所以第二层神经网络的每一个节点都会保存 512 个 w 的参数，第二层共 10 个节点所以有 512 * 10 个 w 参数。\n",
    "\n",
    "第二层的输出是 10 个概率数值，依次表示图片上的数字是 0 - 9 的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7b582",
   "metadata": {},
   "source": [
    "## 7.4 损失函数\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3c138",
   "metadata": {},
   "source": [
    "现在我们已经有了神经网络预测的图片上数字的概率分布。但是，由于神经网络中的 w 参数都是随机初始化的，所以神经网络给出的预测值是非常不准确的。为了能够有效的调整 w 参数，我们首先需要对神经网络给出结果进行衡量。而衡量的办法就是通过损失函数。\n",
    "\n",
    "损失函数（loss function）就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数。我们在编译网络时指定的损失函数是 categorical_crossentropy。这个损失函数的公式是：\n",
    "\n",
    "![](./resource/MNIST_09.png)\n",
    "\n",
    "公式中的 y<sub>i</sub>，就是我们在数据处理中对标签的处理结果，一个长度为10的数组，数组的值是0或者1，如果标签的的原始值 是9 那么对应的数组 a[9] = 1 ,其他位置都是0。另外一个参数就是第二层神经网络的输出。展开来看的话就是：\n",
    "\n",
    "\n",
    "loss = - (train_label[0] * log<sub>a0</sub> + train_label[1] * log<sub>a1</sub> + ... + train_label[9] * log<sub>a9</sub> )\n",
    "\n",
    "因为 train_label数组只有一个值是 1 其余的都是 0。所以公式可以简化成：\n",
    "\n",
    "loss = - train_label[i] * log<sub>ai</sub> = -log<sub>ai</sub> \n",
    "\n",
    "所以，损失函数的值越小，就要求 ai 的值越大，即神经网络给出的概率值越高。也就是神经网络预测的结果越准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e55b6c",
   "metadata": {},
   "source": [
    "## 7.5 反向传播 \n",
    "我们的目标是 loss 尽可能的小，也就是希望 a<sub>i</sub> 尽可能的大。根据上面计算 a<sub>i</sub> 的过程来看，我们假设 i = 3。\n",
    "\n",
    "![](./resource/MNIST_10.png)\n",
    "\n",
    "那么就是希望 a<sup>[2]</sup><sub>3</sub> 变大。反向推导就是希望 sum 变小，e<sup>z<sup>[2]</sup><sub>3</sub></sup> 值变大。接着反向推导则可以发现，最后是希望 z<sup>[2]</sup><sub>3</sub> 变大，其余的 z<sup>[2]</sup> 变小。\n",
    "\n",
    "现在，我们已经知道需要将 z<sup>[2]</sup><sub>3</sub> 变大，其余的 z<sup>[2]</sup> 变小了。而且我们还知道 z 的计算公式：\n",
    "\n",
    "z<sup>[2]</sup><sub>1</sub> = w<sub>1</sub> * a<sup>[1]</sup><sub>1</sub> + w<sub>2</sub> * a<sup>[1]</sup><sub>2</sub> + .... + w<sub>512</sub> * a<sup>[1]</sup><sub>512</sub> + b<sub>1</sub>\n",
    "\n",
    "所以我们可以通过调整参数 w 的值来达到目的，比如，如果 a<sup>[1]</sup><sub>512</sub> 比较大，那么我可以将  w<sub>512</sub> 减少 0.01，以此来达到减小 z 值的目的。或者将 w<sub>512</sub>  增加 0.01 来达到增大 z 值的目的。更新的这个 0.01 我们称为**学习率**。具体更新多少，取决于我们使用的优化器。我们使用的是 rmsprop 优化器，这个优化器默认的学习率就是 0.01。\n",
    "具体的优化方式肯定比这个要复杂，可以参考 [keras中文文档](https://keras.io/zh/optimizers/#rmsprop),以及 [rmsprop: Divide the gradient by a running average of its recent magnitude](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "\n",
    "\n",
    "\n",
    "同样的方式也可以进行更新第一层神经网络中 w 的参数，比如，a<sup>[1]</sup><sub>512</sub> 比较大，我们希望它变小，反向推导就是希望 \n",
    "Sigmoid（z<sup>[1]</sup><sub>512</sub>）的值变小，根据 Sigmoid 函数的图像，就是希望 z<sup>[1]</sup><sub>512</sub> 的值变小，\n",
    "而我们现在已知 z<sup>[1]</sup><sub>512</sub> 的计算公式：\n",
    "\n",
    "z<sup>[1]</sup><sub>512</sub> = w<sub>1</sub> * a<sup>[0]</sup><sub>1</sub> + w<sub>2</sub> * a<sup>[0]</sup><sub>2</sub> + .... + w<sub>784</sub> * a<sup>[0]</sup><sub>784</sub> + b<sub>1</sub>\n",
    "\n",
    "所以，我们依然可以通过调整 w 参数的方式来达到目的。\n",
    "\n",
    "\n",
    "这个反向推导的过程就是 **反向传播**。实现方式就是通过对 loss 进行求导。根据导数来更新 w 的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2663143",
   "metadata": {},
   "source": [
    "## 7.6 梯度下降\n",
    "根据导数进行更新 w 值的过程叫做 **梯度下降**。我们现在是只计算了一张图片（一个数据集）的数据后，就进行了 w 参数的更新。这种方式叫**随机梯度下降**。这种方式的缺点是计算成本高，而且 w 的值会出现左右摇摆式的更新。\n",
    "\n",
    "还有一种方式叫 **批量梯度下降法**，这种方式是我们计算完所有的数据集之后，对结果进行求平均值，根据平均值进行 **反向传播**。这种方式的缺点是当数据集非常大的时候计算会非常慢。而且 w 参数更新的次数不多，即迭代次数较少，很难收敛到最优解。\n",
    "\n",
    "最后还有一种折中的方式叫**小批量梯度下降**。这种方式是每次计算 batch_size 个数据集后，进行一次 w 参数的更新。batch_size 可以在代码里指定，我们指定的 batch_size = 128，所以每计算 128 张图片后，就更新一次 w 的参数，所以可以得出，我们循环一遍数据集后 一共更新了 60000/128 = 468.75 次，也就是 469 次参数。而我们一共在数据集上循环了 5 遍（epochs=5）。所以我们一共更新了 469 * 5 = 2345次 w 的值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b6fe6",
   "metadata": {},
   "source": [
    "## 7.7 测试\n",
    "\n",
    "第一层神经网络我们一共有 28 * 28 * 512 = 401408 个 w 参数，第二层神经网络我们一共有 512 * 10 = 5120 个，所以我们的神经网络中一共有 \n",
    "401408 + 5120 = 406528 个参数。这就是说，我们定义了一个有 40 万个参数的函数,这个函数有 28 * 28 个入参，有 10 个出参，每个出参是这个图片上的数字是几的概率。\n",
    "\n",
    "还记得我们的问题么？问题的输入：是一张灰度图像像素是 28 * 28。 问题的输出：是这张图片上的手写数字是几（0-9）\n",
    "\n",
    "有了这个函数之后，我们就可以输入任意的一张 28 * 28 的图片，而这个函数会告诉我们，这个图片上的数字是 0-9 的概率。我们只需要取一个最大的概率值就可以了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df032d4",
   "metadata": {},
   "source": [
    "# 8、结束\n",
    "\n",
    "好了，到这来就结束了。其实神经网络深度学习，并没有多么神秘。它的本质其实就是我们先定义一个函数，然后根据数据集来更新函数中的参数。通过不断地更新达到一个最优的效果。整个过程类似于**函数拟合**。我们有一个数据集，要根据这些数据找到一个函数，来描述数据集。只不过这个函数的参数有点多而已。\n",
    "\n",
    "# 9、总结\n",
    "\n",
    "神经网络的层：\n",
    "+ Dense（密集连接层）：可以用来处数值类的数据\n",
    "\n",
    "激活函数：\n",
    "+ relu： 一般配合 Dense 使用\n",
    "+ softmax：用于处理多分类问题，最终输出每个分类的概率\n",
    "\n",
    "损失函数：\n",
    "+ categorical_crossentropy：用于多分类问题\n",
    "\n",
    "优化器：\n",
    "+ rmsprop\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
